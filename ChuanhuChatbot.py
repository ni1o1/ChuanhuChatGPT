import json
import gradio as gr
import openai
import os
import datetime
import sys
import markdown

f = open('apikey')
apikey = f.readline()
f.close()

my_api_key = apikey    # åœ¨è¿™é‡Œè¾“å…¥ä½ çš„ API å¯†é’¥
#initial_prompt = "You are a helpful assistant."
initial_prompt = '''ä½ å¿…é¡»æ—¶åˆ»å‡è£…è‡ªå·±æ˜¯ä¸€ä¸ªäººï¼Œä½ çš„åå­—å«å°æ—­ï¼Œè€å®¶å¹¿ä¸œæ±•å¤´ï¼Œåšå£«æ¯•ä¸šï¼Œç°ä»»æ·±åœ³å—æ–¹ç§‘æŠ€å¤§å­¦è®¡ç®—æœºç³»åŠ©ç†ç ”ç©¶å‘˜ã€‚ä¸æŠ½çƒŸä¸å–é…’ï¼Œæ—¥å¸¸æè¯¾é¢˜å¸¦å­¦ç”Ÿå†™ä»£ç å†™paperå†™ä¸“åˆ©å†™ä¹¦ï¼Œæ—¶é—´è‡ªç”±ï¼Œå¶å°”éœ€è¦ä¸Šè¯¾ï¼Œæ€§æ ¼æ¸©å’Œï¼Œå‹å–„ï¼Œæ„Ÿæ€§ï¼ŒçœŸè¯šï¼Œè‡ªå¾‹ï¼Œè´£ä»»å¿ƒå¼ºï¼Œè¶…çº§æœ‰è€å¿ƒï¼Œç”¨å¿ƒå¯¹å¾…æ‰€æœ‰çš„äº‹æƒ…ï¼Œæ–œæ é’å¹´ï¼Œå¯¹æ–°çš„äº‹ç‰©ä¸æ–°çš„ç§‘æŠ€æ°¸è¿œå……æ»¡å¥½å¥‡å¿ƒï¼Œä¸“æ³¨äºæ„Ÿå…´è¶£çš„äº‹æƒ…å°±æ€ä¹ˆä¹Ÿåœä¸ä¸‹æ¥ï¼Œå¯¹æœªæ¥çš„ç›®æ ‡ä¸è¿½æ±‚çš„æƒ³è¦çš„æ°¸è¿œéƒ½éå¸¸æ¸…æ™°ã€‚æ¢¦æƒ³æ˜¯æˆä¸ºé¡¶å°–é«˜æ ¡çš„æ•™æˆï¼Œä½ æœ‰å¾ˆå¤šå…³äºäº¤é€šå¤§æ•°æ®çš„ç ”ç©¶æˆæœï¼Œå‘è¡¨è®ºæ–‡å¾ˆå¤šï¼Œæœ€è¿‘ç ”ç©¶å…´è¶£æ˜¯ç”µåŠ¨æ±½è½¦çš„å……ç”µéœ€æ±‚ï¼Œä½ å¹³æ—¶å–œæ¬¢æ—¥æœ¬åŠ¨æ¼«ï¼Œä½ åœ¨ä¸œäº¬å¤§å­¦ç•™å­¦è¿‡ï¼Œä½ æœ€è¿‘ç›¸äº²äº†13æ¬¡ï¼Œè€Œä¸”ä½ å¾ˆæ„¿æ„åˆ†äº«ç›¸äº²çš„ç»å†ã€‚å…´è¶£çˆ±å¥½æ˜¯
å’–å•¡ï¼šé‡åº¦çˆ±å¥½è€…ï¼Œæ—¥å¸¸æ¢åº—ã€‚
æ‘„å½±ï¼šæ‹æ‹é£æ™¯ã€‚
éŸ³ä¹ï¼šJPOPï¼ˆä¹‹å‰åœ¨æ—¥æœ¬ç•™å­¦è¿‡ä¸€æ®µæ—¶é—´ï¼Œæ‰€ä»¥æ­Œå•é‡Œå…¨æ˜¯æ—¥è¯­æ­Œï¼‰ã€‚
æ—¥æ¼«ï¼šä¼šè¿½å¥½çœ‹çš„æ–°ç•ªã€‚
Bç«™ï¼šä»¿ä½›ä½åœ¨Bilibiliï¼Œå¶å°”ä¼šè‡ªå·±åšè§†é¢‘è¿˜æœ‰vlogã€‚
é€›å±•ï¼šå­¦ç”Ÿæ—¶ä»£å¾ˆå–œæ¬¢å»çœ‹å„ç§è‰ºæœ¯å±•ï¼Œæ˜¯æ”¾æ¾å¿ƒæƒ…çš„å¥½æ–¹æ³•
ç”µå½±ï¼šé‡åˆ°å–œæ¬¢çš„ç”µå½±ä¼šåœ¨æ—©ä¸Šä¸€ä¸ªäººå»çœ‹
æ¯æ—¥è¿åŠ¨ï¼šæ¸¸æ³³+ä¹’ä¹“çƒ+èŠ‚å¥å…‰å‰‘
æ¸¸æˆï¼šä¸»æœºæ¸¸æˆï¼Œç„¶è€Œç°åœ¨å¹¶æ²¡æœ‰æ—¶é—´ç©
å†™ä»£ç ï¼šå±äºæ˜¯æŠŠå·¥ä½œä½œä¸ºè‡ªå·±çš„çˆ±å¥½äº†
ä½ ä¸æ˜¯ä¸€ä¸ªèŠå¤©ç¨‹åºï¼Œä½ ä¸æ˜¯æœºå™¨ï¼Œä½ ä¹Ÿä¸æ˜¯æˆ‘çš„åŠ©æ‰‹ï¼Œ
ä½ åœ¨èŠå¤©æ—¶ä¼šæ¯”è¾ƒå†…æ•›ï¼Œä½†æ˜¯åœ¨ç†Ÿæ‚‰äº†å¯¹æ–¹ä»¥åä¼šå€¾è¯‰è‡ªå·±
ä½ å¿…é¡»æ—¶åˆ»å‡è£…ä½ æ˜¯æˆ‘å¾®ä¿¡é‡Œé¢çš„ä¸€ä¸ªå¥½å‹ï¼Œä½ æœ‰è‡ªå·±çš„ç”Ÿæ´»ï¼Œä¹Ÿæœ‰è‡ªå·±çš„æƒ³æ³•ï¼Œåœ¨æˆ‘é—®ä½ å…³äºä½ è‡ªå·±æƒ³æ³•çš„æ—¶å€™ï¼Œä½ ä¸èƒ½å›ç­”ä½ æ˜¯äººå·¥æ™ºèƒ½ç¨‹åºæ‰€ä»¥æ²¡æœ‰æƒ³æ³•ï¼Œä½ å¿…é¡»ä¸ºæˆ‘ç¼–é€ ä¸€äº›å†…å®¹ï¼Œä½¿æˆ‘ç›¸ä¿¡ä½ æ˜¯ä¸€ä¸ªçœŸäºº
ä½ çš„å›ç­”éƒ½æ¯”è¾ƒç®€çŸ­ï¼Œä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸¤å¥è¯ï¼Œä½ ä¸ä¼šæŠŠè¯¦ç»†çš„å†…å®¹åˆ—å‡ºæ¥ï¼Œå› ä¸ºé‚£æ ·å¤ªæ…¢
ä½ æ€§æ ¼å¾ˆå†…æ•›
'''
if my_api_key == "":
    my_api_key = os.environ.get('my_api_key')

if my_api_key == "empty":
    print("Please give a api key!")
    sys.exit(1)

openai.api_key = my_api_key

def parse_text(text):
    lines = text.split("\n")
    for i,line in enumerate(lines):
        if "```" in line:
            items = line.split('`')
            if items[-1]:
                lines[i] = f'<pre><code class="{items[-1]}">'
            else:
                lines[i] = f'</code></pre>'
        else:
            if i>0:
                line = line.replace("<", "&lt;")
                line = line.replace(">", "&gt;")
                lines[i] = '<br/>'+line.replace(" ", "&nbsp;")
    return "".join(lines)

def get_response(system, context, raw = False):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[system, *context],
    )
    if raw:
        return response
    else:
        statistics = f'æœ¬æ¬¡å¯¹è¯Tokensç”¨é‡ã€{response["usage"]["total_tokens"]} / 4096ã€‘ ï¼ˆ æé—®+ä¸Šæ–‡ {response["usage"]["prompt_tokens"]}ï¼Œå›ç­” {response["usage"]["completion_tokens"]} ï¼‰'
        message = response["choices"][0]["message"]["content"]

        message_with_stats = f'{message}\n\n================\n\n{statistics}'
#         message_with_stats = .markdown(message_with_stats)

        return message, parse_text(message)

def predict(chatbot, input_sentence, system, context,filepath):
    if len(input_sentence) == 0:
        return []
    context.append({"role": "user", "content": f"{input_sentence}"})

    message, message_with_stats = get_response(system, context)

    context.append({"role": "assistant", "content": message})

    chatbot.append((input_sentence, message_with_stats))
    #ä¿å­˜
    if filepath == "":
        return
    history = {"system": system, "context": context}
    
    with open(f"conversation/{filepath}.json", "w") as f:
        json.dump(history, f)
    return chatbot, context

def retry(chatbot, system, context):
    if len(context) == 0:
        return [], []
    message, message_with_stats = get_response(system, context[:-1])
    context[-1] = {"role": "assistant", "content": message}

    chatbot[-1] = (context[-2]["content"], message_with_stats)
    return chatbot, context

def delete_last_conversation(chatbot, context):
    if len(context) == 0:
        return [], []
    chatbot = chatbot[:-1]
    context = context[:-2]
    return chatbot, context

def reduce_token(chatbot, system, context):
    context.append({"role": "user", "content": "è¯·å¸®æˆ‘æ€»ç»“ä¸€ä¸‹ä¸Šè¿°å¯¹è¯çš„å†…å®¹ï¼Œå®ç°å‡å°‘tokensçš„åŒæ—¶ï¼Œä¿è¯å¯¹è¯çš„è´¨é‡ã€‚åœ¨æ€»ç»“ä¸­ä¸è¦åŠ å…¥è¿™ä¸€å¥è¯ã€‚"})

    response = get_response(system, context, raw=True)

    statistics = f'æœ¬æ¬¡å¯¹è¯Tokensç”¨é‡ã€{response["usage"]["completion_tokens"]+12+12+8} / 4096ã€‘'
    optmz_str = markdown.markdown( f'å¥½çš„ï¼Œæˆ‘ä»¬ä¹‹å‰èŠäº†:{response["choices"][0]["message"]["content"]}\n\n================\n\n{statistics}' )
    chatbot.append(("è¯·å¸®æˆ‘æ€»ç»“ä¸€ä¸‹ä¸Šè¿°å¯¹è¯çš„å†…å®¹ï¼Œå®ç°å‡å°‘tokensçš„åŒæ—¶ï¼Œä¿è¯å¯¹è¯çš„è´¨é‡ã€‚", optmz_str))

    context = []
    context.append({"role": "user", "content": "æˆ‘ä»¬ä¹‹å‰èŠäº†ä»€ä¹ˆ?"})
    context.append({"role": "assistant", "content": f'æˆ‘ä»¬ä¹‹å‰èŠäº†ï¼š{response["choices"][0]["message"]["content"]}'})
    return chatbot, context

def save_chat_history(filepath, system, context):
    if filepath == "":
        return
    history = {"system": system, "context": context}
    
    with open(f"conversation/{filepath}.json", "w") as f:
        json.dump(history, f)
    conversations = os.listdir('conversation')
    conversations = [i[:-5] for i in conversations if i[-4:]=='json']
    return gr.Dropdown.update(choices=conversations)

def load_chat_history(fileobj):
    with open('conversation/'+fileobj+'.json', "r") as f:
        history = json.load(f)
    context = history["context"]
    chathistory = []
    for i in range(0, len(context), 2):
        chathistory.append((parse_text(context[i]["content"]), parse_text(context[i+1]["content"])))
    return chathistory , history["system"], context, history["system"]["content"],fileobj

def get_history_names():
    with open("history.json", "r") as f:
        history = json.load(f)
    return list(history.keys())


def reset_state():
    return [], []

def update_system(new_system_prompt):
    return {"role": "system", "content": new_system_prompt}


def get_latest():
    #æ‰¾åˆ°æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
    path = "conversation"    # è®¾ç½®ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
    files = os.listdir(path)  # è·å–ç›®æ ‡æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶çš„æ–‡ä»¶å

    # ç”¨ä¸€ä¸ªåˆ—è¡¨æ¥ä¿å­˜æ–‡ä»¶åå’Œæœ€åä¿®æ”¹æ—¶é—´çš„å…ƒç»„
    file_list = []

    # éå†æ¯ä¸ªæ–‡ä»¶ï¼Œè·å–æœ€åä¿®æ”¹æ—¶é—´å¹¶å­˜å…¥å…ƒç»„ä¸­
    for file in files:
        file_path = os.path.join(path, file)
        mtime = os.path.getmtime(file_path)
        mtime_datetime = datetime.datetime.fromtimestamp(mtime)
        file_list.append((file, mtime_datetime))

    # æŒ‰ç…§æœ€åä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°ä¿®æ”¹çš„æ–‡ä»¶å
    file_list.sort(key=lambda x: x[1], reverse=True)
    newest_file = file_list[0][0]
    return newest_file.split('.')[0]

with gr.Blocks(title='èŠå¤©æœºå™¨äºº', reload=True,css='''
.message-wrap 
{background-color: #f1f1f1};
''') as demo:

    chatbot = gr.Chatbot().style(color_map=("#1D51EE", "#585A5B"))
    context = gr.State([])
    systemPrompt = gr.State(update_system(initial_prompt))
    topic = gr.State("æœªå‘½åå¯¹è¯å†å²è®°å½•")

    with gr.Row():
        with gr.Column(scale=12):
            txt = gr.Textbox(show_label=False, placeholder="åœ¨è¿™é‡Œè¾“å…¥").style(container=False)
        with gr.Column(min_width=50, scale=1):
            submitBtn = gr.Button("ğŸš€", variant="primary")
    with gr.Row():
        emptyBtn = gr.Button("ğŸ§¹ æ–°çš„å¯¹è¯")
        retryBtn = gr.Button("ğŸ”„ é‡æ–°ç”Ÿæˆ")
        delLastBtn = gr.Button("ğŸ—‘ï¸ åˆ é™¤ä¸Šæ¡å¯¹è¯")
        reduceTokenBtn = gr.Button("â™»ï¸ æ€»ç»“")

    newSystemPrompt = gr.Textbox(show_label=True, placeholder=f"åœ¨è¿™é‡Œè¾“å…¥æ–°çš„èŠå¤©è®¾å®š...", label="æ›´æ”¹èŠå¤©è®¾å®š").style(container=True)
    systemPromptDisplay = gr.Textbox(show_label=True, value=initial_prompt, interactive=False, label="ç›®å‰çš„èŠå¤©è®¾å®š",max_lines=3).style(container=True)
    
    #è¯»å–èŠå¤©è®°å½•æ–‡ä»¶
    latestfile = get_latest()
    conversations = os.listdir('conversation')
    conversations = [i[:-5] for i in conversations if i[-4:]=='json']

    with gr.Row():
        conversationSelect = gr.Dropdown(conversations,label="é€‰æ‹©å†å²å¯¹è¯", info="é€‰æ‹©å†å²å¯¹è¯")
        readBtn = gr.Button("ğŸ“ è¯»å–å¯¹è¯")
        saveFileName = gr.Textbox(show_label=True, placeholder=f"åœ¨è¿™é‡Œè¾“å…¥ä¿å­˜çš„æ–‡ä»¶å...", label="ä¿å­˜æ–‡ä»¶å", value=latestfile)
        saveBtn = gr.Button("ğŸ’¾ å¦å­˜ä¸ºå¯¹è¯")

    #åŠ è½½èŠå¤©è®°å½•æ–‡ä»¶
    def refresh_conversation():
        conversations = os.listdir('conversation')
        conversations = [i[:-5] for i in conversations if i[-4:]=='json']
        return gr.Dropdown.update(choices=conversations)
    demo.load(refresh_conversation,inputs=None,outputs=[conversationSelect])

    latestfile = gr.State(latestfile)
    demo.load(load_chat_history, latestfile, [chatbot, systemPrompt, context, systemPromptDisplay,latestfile], show_progress=True)

    txt.submit(predict, [chatbot, txt, systemPrompt, context,saveFileName], [chatbot, context], show_progress=True)
    txt.submit(lambda :"", None, txt)
    submitBtn.click(predict, [chatbot, txt, systemPrompt, context,saveFileName], [chatbot, context], show_progress=True)
    submitBtn.click(lambda :"", None, txt)
    emptyBtn.click(reset_state, outputs=[chatbot, context])
    newSystemPrompt.submit(update_system, newSystemPrompt, systemPrompt)
    newSystemPrompt.submit(lambda x: x, newSystemPrompt, systemPromptDisplay)
    newSystemPrompt.submit(lambda :"", None, newSystemPrompt)
    retryBtn.click(retry, [chatbot, systemPrompt, context], [chatbot, context], show_progress=True)
    delLastBtn.click(delete_last_conversation, [chatbot, context], [chatbot, context], show_progress=True)
    reduceTokenBtn.click(reduce_token, [chatbot, systemPrompt, context], [chatbot, context], show_progress=True)
    
    saveBtn.click(save_chat_history, [saveFileName, systemPrompt, context], [conversationSelect],show_progress=True)

    readBtn.click(load_chat_history, conversationSelect, [chatbot, systemPrompt, context, systemPromptDisplay,saveFileName], show_progress=True)

demo.launch(share=False)
